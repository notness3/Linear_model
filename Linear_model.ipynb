{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSMsQLFCgyvj"
      },
      "source": [
        "# Train loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am5MlEKQXIwB"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from glob import glob\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PMuxyc8Wn9x"
      },
      "source": [
        "class CV_Dataset:\n",
        "  def __init__(self, images_paths, targets, augmentations=None):\n",
        "    self.img_path = images_paths\n",
        "    self.targets = targets\n",
        "    self.augmentations = augmentations\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_path)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image = cv2.imread(self.img_path[idx])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # some image formatting before passing to tensor\n",
        "    if self.augmentations is not None:\n",
        "      img_augmented = self.augmentations(image=image)\n",
        "      image = img_augmented[\"image\"]\n",
        "    if self.targets.shape[0] > 1:\n",
        "      labels = self.targets.iloc[idx]      \n",
        "    else:\n",
        "      labels = self.targets[idx]\n",
        "    sample = {'image': torch.tensor(image), \n",
        "              'targets': torch.tensor(labels)}\n",
        "    return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCmJkUbCWoOo",
        "outputId": "187a9b7a-a401-4b66-a8ab-05a99298c676"
      },
      "source": [
        "!mkdir data\n",
        "num_images = 1000\n",
        "path_to_save_imgs = \"/content/data\"\n",
        "\n",
        "for i in range(num_images):\n",
        "  random_image_np = np.random.randn(32,32,3).astype(np.uint8)\n",
        "  random_image_pil = Image.fromarray(random_image_np)\n",
        "  random_image_pil.save(os.path.join(path_to_save_imgs,f\"{i}.jpg\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDkRzaUcWoer"
      },
      "source": [
        "all_imgs_paths = sorted(glob(f\"{path_to_save_imgs}/*.jpg\"))\n",
        "labels = [np.random.randint(0,10,len(all_imgs_paths)).astype(np.uint8), np.random.randint(0,10,len(all_imgs_paths)).astype(np.uint8)]\n",
        "data = zip(all_imgs_paths,np.array(labels).T.tolist())\n",
        "df = pd.DataFrame(data=data, columns=[\"imgs_path\",\"labels\"])\n",
        "custom_dataset = CV_Dataset(df.imgs_path, df.labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25dqPoIlPVk"
      },
      "source": [
        "class MSE:\n",
        "  def __call__(self, pred, target):\n",
        "    self.target = target\n",
        "    self.pred = pred\n",
        "    return ((target - pred)** 2).mean()\n",
        "\n",
        "  def backward(self):\n",
        "    n = self.target.shape[0]\n",
        "    self.gradient = 2. * (self.pred - self.target) / n\n",
        "    return self.gradient\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UZ4A7G8fOL7"
      },
      "source": [
        "class Linear:\n",
        "  def __init__(self, input_dim, num_hidden=1):\n",
        "    self.weights =  torch.tensor(np.random.randn(input_dim, num_hidden) * np.sqrt(2. / input_dim), dtype = torch.double)\n",
        "    self.bias = torch.tensor(np.zeros(num_hidden), dtype = torch.double)\n",
        "\n",
        "  def __call__(self,x):\n",
        "    self.x = x\n",
        "    return x @ self.weights + self.bias\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    self.weights_gradient = self.x.T @ gradient\n",
        "    self.bias_gradient =  gradient.sum(axis=0)    \n",
        "    self.x_gradient = gradient @ self.weights.T\n",
        "    return self.x_gradient\n",
        "\n",
        "  def update(self, lr):   \n",
        "    self.weights = self.weights - self.weights_gradient* lr\n",
        "    self.bias = self.bias - lr * self.bias_gradient\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQV9-XJUka78"
      },
      "source": [
        "class ReLU:\n",
        "  def __call__(self, input_):\n",
        "    self.input_  = input_\n",
        "    self.output = np.clip(self.input_,0, None)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, output_gradient):\n",
        "    self.input_gradient = (self.input_ > 0) * output_gradient\n",
        "    return self.input_gradient\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Ovzm5Tj0BO"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self,input_dim, num_hidden, num_classes=1):\n",
        "    self.linear1 = Linear(input_dim, num_hidden)\n",
        "    self.relu = ReLU()\n",
        "    self.linear2 = Linear(num_hidden, num_classes)\n",
        "\n",
        "  def __call__(self,x):\n",
        "    l1 = self.linear1(x)\n",
        "    r = self.relu(l1)\n",
        "    l2 = self.linear2(r)\n",
        "    return l2\n",
        "\n",
        "  def backward(self, output_gradient):\n",
        "    linear2_gradient = self.linear2.backward(output_gradient)\n",
        "    relu_gradient = self.relu.backward(linear2_gradient)\n",
        "    linear1_gradient = self.linear1.backward(relu_gradient)\n",
        "    return linear1_gradient\n",
        "\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.linear2.update(lr)\n",
        "    self.linear1.update(lr)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w3wWaOtRvld"
      },
      "source": [
        "train_data, val_data = torch.utils.data.random_split(custom_dataset, [750, 250])\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=4, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=4, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8xe2H-2X8n6"
      },
      "source": [
        "model = Model(3*32*32, 1, 1)\n",
        "loss = MSE()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ0AATcPWd6O",
        "outputId": "8a057335-2ba6-4639-8d91-b45be0ee3e81"
      },
      "source": [
        "def torch_fit(loader, model, loss, lr, num_target=0, num_epochs=1):\n",
        "  for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "       train_im =  torch.tensor(data['image'].view(-1, 3*32*32), dtype = torch.double)\n",
        "       train_tar = torch.tensor(data['targets'][:, num_target:num_target+1], dtype = torch.double)\n",
        "       y_pred_tensor = model(train_im)\n",
        "       loss_value = loss(y_pred_tensor, train_tar)\n",
        "       print(f'Epoch {epoch} --- loss: {loss_value}')\n",
        "       gradient_from_loss = loss.backward()\n",
        "       model.backward(gradient_from_loss)\n",
        "       model.update(lr)\n",
        "       break\n",
        "for i in range(len(custom_dataset[0]['targets'])):\n",
        "  print(f'---Target {i}---')\n",
        "  torch_fit(train_loader, model=model, loss=loss, lr=0.1, num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Target 0---\n",
            "Epoch 0 --- loss: 55.083781726189144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 --- loss: 32.00438274425259\n",
            "Epoch 2 --- loss: 12.930015815780614\n",
            "Epoch 3 --- loss: 18.3786205595772\n",
            "Epoch 4 --- loss: 9.854360458165232\n",
            "Epoch 5 --- loss: 2.9871368799306257\n",
            "Epoch 6 --- loss: 15.624990653791702\n",
            "Epoch 7 --- loss: 7.967494018426687\n",
            "Epoch 8 --- loss: 8.973301080149295\n",
            "Epoch 9 --- loss: 6.142238966536258\n",
            "---Target 1---\n",
            "Epoch 0 --- loss: 8.218532938583204\n",
            "Epoch 1 --- loss: 11.216410551460815\n",
            "Epoch 2 --- loss: 9.619238440937089\n",
            "Epoch 3 --- loss: 2.8353803058295726\n",
            "Epoch 4 --- loss: 7.060964229601803\n",
            "Epoch 5 --- loss: 5.002903772751752\n",
            "Epoch 6 --- loss: 15.131186412496959\n",
            "Epoch 7 --- loss: 6.156715570939941\n",
            "Epoch 8 --- loss: 10.307797965401562\n",
            "Epoch 9 --- loss: 14.204418719542616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}